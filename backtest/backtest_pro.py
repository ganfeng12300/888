# -*- coding: utf-8 -*-
"""
Sæ¡£å›æµ‹ï¼šBayes+GA å¯»ä¼˜ã€å…¨æˆæœ¬ï¼ˆå«å†²å‡»ï¼‰ã€Walk-Forwardã€Deflated Sharpeã€SPAã€PBO æŠ¥å‘Šã€?
ä¸­æ–‡æŠ¥è¡¨å¯¼å‡º + best_combo.csvï¼ˆæœºæ„çº§ç»ˆç‰ˆï¼Œå«ç¨³å¥å‚æ•°æ•´å‹åŒ–ï¼‰
"""
import argparse, os, json, time, sqlite3, numpy as np, pandas as pd
from datetime import datetime
from importlib import import_module
from numbers import Real

# === ä¾èµ–äºé¡¹ç›®å†…æ¨¡å—ï¼ˆä¿æŒä¸æ‚¨ç°æœ‰å·¥ç¨‹ä¸€è‡´ï¼‰ ===
from tools.config import get_db_path, get_results_db, runtime_params
from tools.db_util import connect_ro
from tools.fees_rules import fetch_funding_series, apply_costs, estimate_impact_bps
from strategy.strategies_a1a8 import STRATS
from backtest.stats_validators import (
    equity_metrics, walk_forward_splits, deflated_sharpe,
    spa_significance, probability_of_backtest_overfitting
)
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK

# æ”¯æŒçš„å‘¨æœ?
TFS = ["5m", "15m", "30m", "1h", "2h", "4h", "1d"]

# ---- è¿™äº›å‚æ•°åœ¨ç­–ç•¥ä¸­â€œå¿…é¡»æ˜¯æ•´æ•°â€ï¼Œç»Ÿä¸€åœ¨å…¥å£åšå¼ºåˆ¶æ•´å‹åŒ?----
INT_PARAMS = {
    "lookback","period","atr_n","rsi_n","fast","slow",
    "n_estimators","num_leaves","max_depth","epochs","hidden","window",
}

# å‚æ•°ç©ºé—´ï¼ˆä¸ STRATS ä¸­å‡½æ•°ä¿æŒä¸€è‡´ï¼›é”®ä¸º A1..A8ï¼?
SPACE = {
 "A1": {"period": hp.quniform("period",18,34,2), "n": hp.uniform("n",1.2,2.8)},
 "A2": {"fast": hp.quniform("fast",8,16,2), "slow": hp.quniform("slow",40,70,2)},
 "A3": {"period": hp.quniform("period",12,22,2), "low": hp.quniform("low",20,35,1), "high": hp.quniform("high",60,75,1)},
 "A4": {"atr_n": hp.quniform("atr_n",12,22,2), "k": hp.uniform("k",1.2,2.4)},
 "A5": {"lookback": hp.quniform("lookback",20,50,2), "n_estimators": hp.quniform("n_estimators",150,300,50),
        "num_leaves": hp.quniform("num_leaves",31,63,2), "lr": hp.uniform("lr",0.02,0.08)},
 "A6": {"lookback": hp.quniform("lookback",20,50,2), "n_estimators": hp.quniform("n_estimators",200,400,50),
        "max_depth": hp.quniform("max_depth",4,8,1)},
 "A7": {"lookback": hp.quniform("lookback",24,40,2), "hidden": hp.quniform("hidden",16,48,8), "epochs": hp.quniform("epochs",2,4,1)},
 "A8": {"rsi_n": hp.quniform("rsi_n",12,18,2), "rsi_low": hp.quniform("rsi_low",20,30,1), "atr_n": hp.quniform("atr_n",12,18,2), "k": hp.uniform("k",1.2,2.0)},
}

# ---- è§£æä¸è§£æå™¨å…¼å®¹ï¼šå¤–å±‚å¯èƒ½ä¼ å…¥æœªçŸ¥å¼€å…³ï¼ˆ--spa ç­‰ï¼‰ï¼Œä½¿ç”?parse_known_args() å¿½ç•¥ ----
def build_parser():
    ap = argparse.ArgumentParser()
    ap.add_argument("--db", default=get_db_path())
    ap.add_argument("--days", type=int, default=365)
    ap.add_argument("--topk", type=int, default=40)
    ap.add_argument("--outdir", default="results")
    ap.add_argument("--symbols", nargs="+")
    # å•ç­–ç•¥é€‰æ‹©ï¼ˆä¾›å¤–å±‚å¹¶è¡Œæ€»æ§æ³¨å…¥ A1..A8ï¼?
    ap.add_argument("--only-strategy", dest="only_strategy", default="",
                    help="ä»…è¿è¡ŒæŒ‡å®šç­–ç•¥ï¼šA1..A8ï¼ˆè‹¥ç•™ç©ºåˆ™è¿è¡Œå…¨éƒ?A1..A8ï¼?)
    return ap

# --- å…œåº•è§£æå™¨ï¼ˆå½?STRATS æœªæ³¨å†Œæ—¶å¯»æ‰¾å‡½æ•°ï¼?---
def _resolve_fn(strat_key):
    S = import_module("strategy.strategies_a1a8")
    key = str(strat_key)
    # 1) STRATS æ³¨å†Œ
    if hasattr(S, "STRATS") and key in getattr(S, "STRATS"):
        return getattr(S, "STRATS")[key][1]
    # 2) åŒåå‡½æ•°
    if hasattr(S, key) and callable(getattr(S, key)):
        return getattr(S, key)
    # 3) å¸¸è§åˆ«åï¼ˆGPUï¼?
    alias = {"XGB":"strat_xgb_gpu","LGBM":"strat_lgbm_gpu","LSTM":"strat_lstm_gpu"}
    name = alias.get(key.upper())
    if name and hasattr(S, name) and callable(getattr(S, name)):
        return getattr(S, name)
    # 4) æ¨¡ç³Šå…³é”®å­—å…œåº?
    names=[n for n in dir(S) if n.startswith("strat_") and callable(getattr(S,n,None))]
    low={n.lower():n for n in names}
    kw_map={"A1":["bbands","band"],"A2":["ma_cross","cross","don","break","channel","bo"],
            "A3":["rsi"],"A4":["atr","break"],"A7":["lstm"]}
    for kw in kw_map.get(key.upper(),[]):
        for ln,orig in low.items():
            if kw in ln:
                return getattr(S, orig)
    raise KeyError(f"Unknown strategy: {strat_key}")

# ---- å¼ºåˆ¶æŠŠå¿…é¡»æ•´å‹çš„å‚æ•°è½¬æˆæ•´æ•°ï¼ˆå« numpy æ ‡é‡ï¼?----
def _coerce_params(params: dict) -> dict:
    out={}
    for k,v in (params or {}).items():
        try:
            if isinstance(v, Real) and np.isfinite(v):
                vf=float(v)
                if k in INT_PARAMS:
                    iv = int(round(vf))
                    out[k] = max(1, iv)     # çª—å£è‡³å°‘ä¸?1
                else:
                    out[k] = vf
            else:
                out[k]=v
        except Exception:
            out[k]=v
    return out

def read_klines(db, table):
    with connect_ro(db) as con:
        try:
            df=pd.read_sql_query(f'SELECT ts, open, high, low, close, volume FROM "{table}" ORDER BY ts ASC', con)
            return df if not df.empty else None
        except Exception:
            return None

def backtest_once(df, strat_key, params, rp, symbol, tf):
    # ä¼˜å…ˆä½¿ç”¨ STRATSï¼›ä»…å½“ç¼ºå¤±æ—¶æ‰ç”¨è§£æå™?
    name, fn = STRATS.get(strat_key, (strat_key, None))
    if not callable(fn):
        fn = _resolve_fn(strat_key)

    # --- è¿›å…¥ç­–ç•¥å‰å¼ºåˆ¶æ•´å‹åŒ– ---
    p_clean = _coerce_params(params)

    pos = fn(df, **p_clean)

    close=pd.to_numeric(df["close"], errors="coerce").astype(float)
    ret = pos.shift(1).fillna(0.0) * close.pct_change().fillna(0.0)

    # é˜²æç«¯æ•°æ®å¯¼è‡´æ•°å€¼çˆ†ç‚?
    ret = ret.clip(-0.5, 0.5)

    # èµ„é‡‘è´¹ç‡ï¼ˆè‹¥å¼€å¯ï¼‰
    fund_df=None
    if rp.get("funding_on", False):
        try:
            fund_df=fetch_funding_series(symbol, int(df["ts"].iloc[0]), int(df["ts"].iloc[-1]))
        except Exception:
            fund_df=None

    # å†²å‡»æˆæœ¬ä¼°è®¡ï¼ˆä»¥20æ—¥å¹³å‡åä¹‰ADVä¸ºè¿‘ä¼¼ï¼‰
    adv_usdt = float((close*pd.to_numeric(df["volume"]).fillna(0)).rolling(24*20).mean().dropna().median() or 1e6)
    # è¿›å‡ºåä¹‰ï¼ˆé£é™©é¢„ç®—è¿‘ä¼¼â†’åä¹‰ï¼?
    notional_series = pos.diff().abs().fillna(0.0) * (rp["risk_per_trade"]/max(0.004,0.01))
    impact_bps = estimate_impact_bps(notional_series, adv_usdt, kappa=15.0)

    ret = apply_costs(ret, pos, taker_fee=rp["taker_fee"], slippage=rp["slippage"],
                      funding_df=fund_df, bar_ts=df["ts"].tolist(), impact_bps_series=impact_bps)

    eq=(1+ret.fillna(0.0)).cumprod()
    met=equity_metrics(eq)
    trades=int(((pos.diff()!=0)&(pos==1)).sum())
    winrate=float((ret[ret!=0]>0).mean()*100) if trades>0 else np.nan

    return {
        "Symbol":symbol,"æ—¶é—´å‘¨æœŸ":tf,"ç­–ç•¥":strat_key,"å‚æ•°JSON":json.dumps(p_clean,ensure_ascii=False),
        "æ€»æ”¶ç›?%)":met["æ€»æ”¶ç›?%)"],"å¹´åŒ–(%)":met["å¹´åŒ–(%)"],"å¤æ™®æ¯?:met["å¤æ™®æ¯?],"èƒœç‡(%)":winrate,
        "äº¤æ˜“æ¬¡æ•°":trades,"æœ€å¤§å›æ’?%)":met["æœ€å¤§å›æ’?%)"],
        "æ‰‹ç»­è´¹æ»‘ç‚¹æˆæœ?%)":float(((rp["taker_fee"]+rp["slippage"]) * trades)*100),
        "èµ„é‡‘è´¹ç‡å½±å“(%)":0.0,"å†²å‡»æˆæœ¬(%)":float(impact_bps.fillna(0).sum()/100.0),
        "pos":pos, "ret":ret, "eq":eq
    }

def bayes_ga_optimize(df, symbol, tf, strat_key, rp, n_bayes=25, n_ga=20, elite=10):
    space=SPACE[strat_key]
    results=[]
    def objective(p):
        res=backtest_once(df, strat_key, p, rp, symbol, tf)
        # æœºæ„çº§ç»¼åˆè¯„åˆ†ï¼ˆå¯æŒ‰éœ€å¾®è°ƒæƒé‡ï¼?
        score = 0.5*(res["å¤æ™®æ¯?]/3.0) + 0.3*(res["æ€»æ”¶ç›?%)"]/100.0) - 0.2*(res["æœ€å¤§å›æ’?%)"]/50.0)
        results.append(res)
        return {"loss": -score, "status": STATUS_OK}

    trials=Trials()
    fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=n_bayes, trials=trials, rstate=np.random.default_rng(42))

    # ç²¾è‹±è§£åš GA å±€éƒ¨å˜å¼‚ï¼ˆæ³¨æ„ï¼šå¯¹ INT_PARAMS çš„å‚æ•°ï¼Œå˜å¼‚åä¹Ÿå¼ºåˆ¶å›æ•´å‹ï¼‰
    elite_rows=sorted(results, key=lambda r: (-r["æ€»æ”¶ç›?%)"], -r["å¤æ™®æ¯?]))[:elite]
    def mutate(p):
        q=dict(p)
        for k in space.keys():
            v=q.get(k)
            if isinstance(v,(int,float,Real)):
                try:
                    nv = float(v)*(1+np.random.normal(0,0.1))
                    if k in INT_PARAMS:
                        q[k] = max(1, int(round(nv)))
                    else:
                        q[k] = nv
                except Exception:
                    pass
        return q

    for _ in range(n_ga):
        base=np.random.choice(elite_rows)
        cand=mutate(json.loads(base["å‚æ•°JSON"]))
        cand=_coerce_params(cand)
        results.append(backtest_once(df, strat_key, cand, rp, symbol, tf))

    return results

def walk_forward_validate(df, strat_key, best_params, rp, symbol, tf, kfold=5):
    n=len(df)
    splits=walk_forward_splits(n, k=kfold)
    oos=[]
    for i,(a,b) in enumerate(splits):
        sub=df.iloc[:b].copy()
        res=backtest_once(sub, strat_key, best_params, rp, symbol, tf)
        eq=res["eq"]; oos.append(eq.iloc[-1]-1.0)
    oos_ret=np.array([float(x) for x in oos if pd.notna(x)])
    return (oos_ret.mean()*100.0) if len(oos_ret)>0 else np.nan

def main():
    # ç¯å¢ƒ/GPUä¿¡æ¯ï¼ˆå¦‚æ— åˆ™å¿½ç•¥ï¼?
    try:
        from utils.gpu_accel import log_env
        log_env()
    except Exception:
        pass

    ap = build_parser()
    # å…³é”®ï¼šæ¥å—å¤–å±‚æœªçŸ¥å‚æ•°ï¼ˆ--spa/--pbo/--impact-recheck/...ï¼?
    args, _unknown = ap.parse_known_args()
    rp = runtime_params()

    os.makedirs(args.outdir, exist_ok=True)
    os.makedirs("data", exist_ok=True)

    # è‡ªåŠ¨å‘ç°/æ•´ç†ç¬¦å·
    if args.symbols:
        symbols = sorted(set(s.upper() for s in args.symbols))
    else:
        with connect_ro(args.db) as con:
            rows=con.execute("SELECT name FROM sqlite_master WHERE type='table'").fetchall()
        got=set()
        for (tb,) in rows:
            if "_" in tb:
                s,tf=tb.split("_",1)
                if tf in TFS: got.add(s)
        symbols=sorted(got)[:80]  # ä¸Šé™ä¿æŠ¤

    print(f"[å›æµ‹] ç¬¦å·æ•?{len(symbols)} çª—å£={args.days}å¤?Sæ¡?ON")

    # é€‰å®šè¦è·‘çš„ç­–ç•¥åˆ—è¡¨ï¼ˆæ”¯æŒ --only-strategy A1..A8ï¼›å¦åˆ™å…¨éƒ¨ï¼‰
    if args.only_strategy:
        sel = args.only_strategy.strip().upper()
        if sel not in SPACE.keys():
            raise SystemExit(f"[ERROR] unknown --only-strategy: {args.only_strategy}")
        strategies_to_run = [sel]
    else:
        strategies_to_run = list(SPACE.keys())  # A1..A8

    all_rows=[]
    cutoff_utc_ms = int(pd.Timestamp.utcnow().value//10**6) - args.days*24*3600*1000

    for s in symbols:
        for tf in TFS:
            df=read_klines(args.db, f"{s}_{tf}")
            if df is None or df.empty: continue
            df=df[df["ts"]>=cutoff_utc_ms]
            if len(df)<200: continue

            for strat_key in strategies_to_run:
                try:
                    rs=bayes_ga_optimize(df, s, tf, strat_key, rp)
                    all_rows.extend(rs)
                except Exception as e:
                    # å•ç­–ç•¥å¤±è´¥ä¸ä¸­æ–­å…¨å±€ï¼ˆä¸å¤–å±‚å®¹é”™ä¸€è‡´ï¼‰
                    print(f"[WARN] {s} {tf} {strat_key} failed: {e}")

    if not all_rows:
        print("æ— ç»“æ?); return

    # æ±‡æ€?â†?ç¨³å¥æ€?æ ¡æ­£
    df_all=pd.DataFrame([{k:v for k,v in r.items() if k not in ["pos","ret","eq"]} for r in all_rows])
    gcols=["Symbol","æ—¶é—´å‘¨æœŸ","ç­–ç•¥","å‚æ•°JSON"]
    df_best=(df_all.sort_values(["Symbol","æ—¶é—´å‘¨æœŸ","ç­–ç•¥","æ€»æ”¶ç›?%)","å¤æ™®æ¯?], ascending=[True,True,True,False,False])
                  .groupby(gcols, as_index=False).head(1))

    # æ¯ä¸ªå¸ä¿ç•™å”¯ä¸€æœ€ä½³ï¼ˆå¤šå‘¨æœŸè‡ªåŠ¨é€‰ä¼˜ï¼?
    keep=[]
    for sym, g in df_best.groupby("Symbol"):
        best=(g.sort_values(["æ€»æ”¶ç›?%)","å¤æ™®æ¯?,"èƒœç‡(%)"], ascending=[False,False,False]).head(1))
        keep.append(best)
    best_per_symbol=pd.concat(keep, ignore_index=True)

    # Walk-Forwardã€Deflated Sharpeã€SPAã€PBO
    oos_list=[]; ds_list=[]; spa_list=[]; pbo_list=[]
    for i,row in best_per_symbol.iterrows():
        s=row["Symbol"]; tf=row["æ—¶é—´å‘¨æœŸ"]; strat=row["ç­–ç•¥"]; params=json.loads(row["å‚æ•°JSON"])
        df=read_klines(args.db, f"{s}_{tf}")
        if df is None: 
            oos_list.append(np.nan); ds_list.append(np.nan); spa_list.append("å?); pbo_list.append(np.nan)
            continue
        df=df[df["ts"]>=cutoff_utc_ms]
        oos=walk_forward_validate(df, strat, params, rp, s, tf, kfold=5)
        ds=deflated_sharpe(row["å¤æ™®æ¯?], n_strats=max(1,len(df_all)), n_obs=len(df))
        g=df_all[(df_all["Symbol"]==s) & (df_all["æ—¶é—´å‘¨æœŸ"]==tf)]
        sig,p = spa_significance(g["æ€»æ”¶ç›?%)"].fillna(0).values)
        pbo = probability_of_backtest_overfitting(g["æ€»æ”¶ç›?%)"].rank().values,
                                                  g["å¤æ™®æ¯?].rank().values)
        oos_list.append(oos); ds_list.append(ds); spa_list.append("æ˜? if sig else "å?); pbo_list.append(pbo)

    best_per_symbol["æ ·æœ¬å¤–æ”¶ç›?%)"]=oos_list
    best_per_symbol["å»æ°´åˆ†å¤æ™?]=ds_list
    best_per_symbol["SPAæ˜¾è‘—æ€?æ˜?å?"]=spa_list
    best_per_symbol["PBO(è¿‡æ‹Ÿåˆæ¦‚ç?"]=pbo_list
    best_per_symbol["ç¨³å¥æ€§é€šè¿‡(æ˜?å?"]=["æ˜? if (a>=0 and b=='æ˜?) else "å? for a,b in zip(oos_list, spa_list)]

    # å¯¼å‡ºä¸­æ–‡æŠ¥è¡¨
    ts_str=datetime.now().strftime("%Y%m%d-%H%M%S")
    path1=os.path.join(args.outdir, f"æœ€ä¼˜ç»„åˆæ€»è¡¨_Sæ¡£_{ts_str}.csv")
    path2=os.path.join(args.outdir, f"å…¨é‡å›æµ‹æ˜ç»†_Sæ¡£_{ts_str}.csv")
    path3=os.path.join(args.outdir, f"å‚æ•°å¯»ä¼˜è½¨è¿¹_Sæ¡£_{ts_str}.csv")
    path4=os.path.join(args.outdir, f"ç¨³å¥æ€§ä¸æ£€éªŒæŠ¥å‘Š_Sæ¡£_{ts_str}.csv")

    best_per_symbol.drop(columns=["pos","ret","eq"], errors="ignore").to_csv(path1, index=False, encoding="utf-8-sig")
    df_all.drop(columns=["pos","ret","eq"], errors="ignore").to_csv(path2, index=False, encoding="utf-8-sig")
    df_all[["Symbol","æ—¶é—´å‘¨æœŸ","ç­–ç•¥","å‚æ•°JSON","æ€»æ”¶ç›?%)","å¤æ™®æ¯?,"æœ€å¤§å›æ’?%)","èƒœç‡(%)","äº¤æ˜“æ¬¡æ•°"]].to_csv(path3, index=False, encoding="utf-8-sig")
    best_per_symbol[["Symbol","æ—¶é—´å‘¨æœŸ","ç­–ç•¥","å‚æ•°JSON","æ ·æœ¬å¤–æ”¶ç›?%)","å»æ°´åˆ†å¤æ™?,"SPAæ˜¾è‘—æ€?æ˜?å?","PBO(è¿‡æ‹Ÿåˆæ¦‚ç?","ç¨³å¥æ€§é€šè¿‡(æ˜?å?"]].to_csv(path4, index=False, encoding="utf-8-sig")

    # best_combo.csvï¼ˆæœºå™¨å‹å¥½ï¼Œå®ç›˜ä½¿ç”¨ï¼?
    os.makedirs("data", exist_ok=True)
    best_combo_path="D:\\SHUJU888\\data\\best_combo.csv"
    out_cols=["Symbol","æ—¶é—´å‘¨æœŸ","ç­–ç•¥","å‚æ•°JSON","æ€»æ”¶ç›?%)","å¤æ™®æ¯?,"æœ€å¤§å›æ’?%)","èƒœç‡(%)","äº¤æ˜“æ¬¡æ•°"]
    best_per_symbol[out_cols].to_csv(best_combo_path, index=False, encoding="utf-8-sig")

    # ç®€å?PBO å¯è§†åŒ–ï¼ˆhtmlï¼?
    try:
        import matplotlib.pyplot as plt
        fig,ax=plt.subplots(figsize=(7,4))
        ax.hist(best_per_symbol["PBO(è¿‡æ‹Ÿåˆæ¦‚ç?"].fillna(0), bins=10)
        ax.set_title("PBO åˆ†å¸ƒï¼ˆè¶Šä½è¶Šå¥½ï¼‰"); ax.set_xlabel("PBO"); ax.set_ylabel("é¢‘æ•°")
        html=os.path.join(args.outdir, f"PBOæŠ¥å‘Š_Sæ¡£_{ts_str}.html")
        import io, base64
        buf=io.BytesIO(); plt.tight_layout(); plt.savefig(buf, format="png"); data=base64.b64encode(buf.getvalue()).decode()
        with open(html,"w",encoding="utf-8") as f:
            f.write(f"<img src='data:image/png;base64,{data}'/>")
    except Exception:
        pass

    print(f"[å®Œæˆ] æœ€ä¼˜è¡¨: {path1}")
    print(f"[å®Œæˆ] best_combo: {best_combo_path}")

if __name__=="__main__":
    main()
